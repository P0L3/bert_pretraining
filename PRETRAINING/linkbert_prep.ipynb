{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1414ab8",
   "metadata": {},
   "source": [
    "A notebook to explore availability of data for LinkBERT style pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789d671",
   "metadata": {},
   "source": [
    "## 0 Data an Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40350ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b40ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"DATASET/ED4RE_2503/ED4RE_2603.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc941ec7",
   "metadata": {},
   "source": [
    "## 1 Initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe89ec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Analysis of Reference Column Structure\n",
      "============================================================\n",
      "Total documents with potential references: 171,880\n",
      "Documents with references as a list (good format): 162,726 (94.67%)\n",
      "Documents with references as a single string (needs parsing): 9,154 (5.33%)\n",
      "\n",
      "\n",
      "--- For List-Formatted References Only ---\n",
      "count    162726.000000\n",
      "mean         52.317902\n",
      "std         583.275877\n",
      "min           0.000000\n",
      "25%          33.000000\n",
      "50%          45.000000\n",
      "75%          60.000000\n",
      "max      169759.000000\n",
      "Name: num_references, dtype: float64\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 1: Calculate the number of references for each document ---\n",
    "def get_reference_count(ref_entry):\n",
    "    if isinstance(ref_entry, list):\n",
    "        return len(ref_entry)\n",
    "    elif ref_entry == \"no_references\":\n",
    "        return 0\n",
    "    else: # This handles strings and other non-list types\n",
    "        return 1\n",
    "\n",
    "# Apply this function to create a new column with the counts\n",
    "df['num_references'] = df['References'].apply(get_reference_count)\n",
    "\n",
    "\n",
    "# --- Step 2: Get high-level statistics ---\n",
    "\n",
    "# First, let's count how many are neatly structured vs. single blobs\n",
    "is_list_mask = df['References'].apply(lambda x: isinstance(x, list))\n",
    "list_count = is_list_mask.sum()\n",
    "string_blob_count = len(df) - list_count\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Analysis of Reference Column Structure\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total documents with potential references: {len(df):,}\")\n",
    "print(f\"Documents with references as a list (good format): {list_count:,} ({list_count/len(df):.2%})\")\n",
    "print(f\"Documents with references as a single string (needs parsing): {string_blob_count:,} ({string_blob_count/len(df):.2%})\")\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# # Now, let's get descriptive statistics on the 'num_references' column\n",
    "# print(\"=\"*60)\n",
    "# print(\"Descriptive Statistics for Number of References per Document\")\n",
    "# print(\"=\"*60)\n",
    "# # The describe() output will be heavily influenced by the single-string blobs (value=1)\n",
    "# # so we'll show stats for both all data and just the list-formatted data.\n",
    "# print(\"--- Overall (including single-string blobs as 1) ---\")\n",
    "# print(df['num_references'].describe())\n",
    "# print(\"\\n\")\n",
    "\n",
    "# Filter for only the documents that had a list to get a cleaner distribution\n",
    "df_lists_only = df[is_list_mask]\n",
    "print(\"--- For List-Formatted References Only ---\")\n",
    "print(df_lists_only['num_references'].describe())\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed335418",
   "metadata": {},
   "source": [
    "**Observation 1**:\n",
    "\n",
    "Total documents with potential references: 171,880\n",
    "Documents with references as a list (good format): 162,726 (94.67%)\n",
    "Documents with references as a single string (needs parsing): 9,154 (5.33%)\n",
    "\n",
    "count    162726\n",
    "mean         52.317902\n",
    "std         583.275877\n",
    "min           0\n",
    "25%          33\n",
    "50%          45\n",
    "75%          60\n",
    "max      169759\n",
    "\n",
    "75% of references are lists that contain up to 60 references, this seems like a reasonable maximum number? Let's look at a random sample to feel the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1a409bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extreme enrichment in atmosphericNN\n",
      "extreme enrichment in atmosphericnn\n",
      "\n",
      "V a r i a t i o n s   i n   T I M P 3   a r e   a s s o c i a t e d   w i t h   a g e - r e l a t e d   m a c u l a r   d e g e n e r a t i o n\n",
      "variations in timp3 are associated with agerelated macular degeneration\n",
      "\n",
      "H i g h - p r e c i s i o n   d a t i n g   o f   c o l o n i z a t i o n   a n d   s e t t l e m e n t   i n   E a s t   P o l y n e s i a\n",
      "highprecision dating of colonization and settlement in east polynesia\n",
      "\n",
      "E d i t o r i a l — M o d e l l i n g   o f   F l o o d s   i n   U r b a n   A r e a s\n",
      "editorialmodelling of floods in urban areas\n",
      "\n",
      "S m a l l e r   h u m a n   p o p u l a t i o n   i n   2 1 0 0   c o u l d   i m p o r t a n t l y   r e d u c e   t h e   r i s k   o f   c l i m a t e   c a t a s t r o p h e\n",
      "smaller human population in 2100 could importantly reduce the risk of climate catastrophe\n",
      "\n",
      "T h e   p a n d e m i c   i s   p r o m p t i n g   w i d e s p r e a d   u s e — a n d   m i s u s e — o f   r e a l - w o r l d   d a t a\n",
      "the pandemic is prompting widespread useand misuseof realworld data\n",
      "\n",
      "T h e   T h r e a t e n e d   S p e c i e s   I m p e r a t i v e :   C o n s e r v a t i o n   a s s e s s m e n t s   w o u l d   b e n e f i t   f r o m   p o p u l a t i o n   g e n o m i c   i n s i g h t s\n",
      "the threatened species imperative conservation assessments would benefit from population genomic insights\n",
      "\n",
      "R e p l y   t o   S c r e e n   a n d   S i m m o n d s :   F r o m   m e a n s   t o   m e c h a n i s m s\n",
      "reply to screen and simmonds from means to mechanisms\n",
      "\n",
      "Weakening Atlantic Niño–Pacific connection under greenhouse warming\n",
      "weakening atlantic niñopacific connection under greenhouse warming\n",
      "\n",
      "Q n A s   w i t h   H u g o   J .   B e l l e n\n",
      "qnas with hugo j bellen\n",
      "\n",
      "M o r t g a g i n g   t h e   f u t u r e   o f   c h i n e s e   p a l e o n t o l o g y\n",
      "mortgaging the future of chinese paleontology\n",
      "\n",
      "R e p l y   t o   B r e t t e l   a n d   B y r d i n :   O n   t h e   e f f i c i e n c y   o f   D N A   r e p a i r   b y   p h o t o l y a s e\n",
      "reply to brettel and byrdin on the efficiency of dna repair by photolyase\n",
      "\n",
      "R e p l y   t o   W a m p l e r   e t   a l . :   D e f o r e s t a t i o n   a n d   b i o d i v e r s i t y   l o s s   s h o u l d   n o t   b e   s u g a r c o a t e d\n",
      "reply to wampler et al deforestation and biodiversity loss should not be sugarcoated\n",
      "\n",
      "R e p l y   t o   D o n g   a n d   Z h a o :   P l a n t   s t r e s s   v i a   R a m a n   s p e c t r o s c o p y\n",
      "reply to dong and zhao plant stress via raman spectroscopy\n",
      "\n",
      "R e p l y   t o   T a l l   e t   a l . :   D i c t y o s t e l i u m   R i c 8   d o e s   n o t   h a v e   a   c h a p e r o n i n g   f u n c t i o n   d u r i n g   d e v e l o p m e n t   a n d   c h e m o t a x i s\n",
      "reply to tall et al dictyostelium ric8 does not have a chaperoning function during development and chemotaxis\n",
      "\n",
      "R e p l y   t o   J o r d á n - G a r z a   e t   a l . :   D e m o g r a p h i c   d y n a m i s m   a s   a n   a d d i t i o n a l   m e c h a n i s m   o f   c o r a l   d i s e a s e   r e s i s t a n c e\n",
      "reply to jordángarza et al demographic dynamism as an additional mechanism of coral disease resistance\n",
      "\n",
      "A   m a s s i v e   s t a r   d i e s   w i t h o u t   a   b a n g ,   r e v e a l i n g   t h e   s e n s i t i v e   n a t u r e   o f   s u p e r n o v a e\n",
      "a massive star dies without a bang revealing the sensitive nature of supernovae\n",
      "\n",
      "P r o f i l e   o f   P e t e r   N o v i c k\n",
      "profile of peter novick\n",
      "\n",
      "D y n a m i c s   o f   V e g e t a t i o n   a n d   C l i m a t e   C h a n g e\n",
      "dynamics of vegetation and climate change\n",
      "\n",
      "Q n A s   w i t h   G i l b e r t   S t r a n g\n",
      "qnas with gilbert strang\n",
      "\n",
      "W h y   i t   m a k e s   s e n s e   t h a t   i n c r e a s e d   P M 2 . 5   w a s   c o r r e l a t e d   w i t h   a n t h r o p o g e n i c   c o m b u s t i o n - d e r i v e d   w a t e r\n",
      "why it makes sense that increased pm25 was correlated with anthropogenic combustionderived water\n",
      "\n",
      "H o w   d o e s   C a M K I I δ   p h o s p h o r y l a t i o n   o f   t h e   c a r d i a c   r y a n o d i n e   r e c e p t o r   c o n t r i b u t e   t o   i n o t r o p y ?\n",
      "how does camkiiδ phosphorylation of the cardiac ryanodine receptor contribute to inotropy\n",
      "\n",
      "R e p l y   t o   B e d l a c k   e t   a l . :   A   s m a l l   p i l o t   s t u d y   c a l l s   f o r   l a r g e   c l i n i c a l   t r i a l s   t o   e v a l u a t e   t h e   e f f e c t s   o f   l i t h i u m   b e f o r e   p r e s c r i b i n g   t h e   d r u g   f o r   a m y o t r o p h i c   l a t e r a l   s c l e r o s i s\n",
      "reply to bedlack et al a small pilot study calls for large clinical trials to evaluate the effects of lithium before prescribing the drug for amyotrophic lateral sclerosis\n",
      "\n",
      "E s t i m a t i n g   t h e   g l o b a l   n u m b e r   o f   t r o p i c a l   t r e e   s p e c i e s ,   a n d   F i s h e r ’ s   p a r a d o x\n",
      "estimating the global number of tropical tree species and fishers paradox\n",
      "\n",
      "A l g o r i t h m i c   O p t i m a l   M a n a g e m e n t   o f   a   P o t a b l e   W a t e r   D i s t r i b u t i o n   S y s t e m :   A p p l i c a t i o n   t o   t h e   P r i m a r y   N e t w o r k   o f   B o n a b e r i   ( D o u a l a ,   C a m e r o o n )\n",
      "algorithmic optimal management of a potable water distribution system application to the primary network of bonaberi douala cameroon\n",
      "\n",
      "N o t   s u r p r i s i n g l y ,   n o   i n h e r i t a n c e   o f   a   t r a i t   r e s u l t s   i n   n o   e v o l u t i o n\n",
      "not surprisingly no inheritance of a trait results in no evolution\n",
      "\n",
      "Q n A s   w i t h   A n g e l   R u b i o\n",
      "qnas with angel rubio\n",
      "\n",
      "Enhanced North American carbon uptake associated with El Niño\n",
      "enhanced north american carbon uptake associated with el niño\n",
      "\n",
      "Gravel-bed river floodplains are the ecological nexus of glaciated mountain landscapes\n",
      "gravelbed river floodplains are the ecological nexus of glaciated mountain landscapes\n",
      "\n",
      "S t e p h e n   H a w k i n g   ( 1 9 4 2 – 2 0 1 8 ) :   T o w a r d   a   c o m p l e t e   u n d e r s t a n d i n g   o f   t h e   u n i v e r s e\n",
      "stephen hawking 19422018 toward a complete understanding of the universe\n",
      "\n",
      "R e p l y   t o   M u r a l i   e t   a l . :   P r o t o n   t r a n s l o c a t i o n   s t o i c h i o m e t r y   o f   c b b 3 - t y p e   c y t o c h r o m e   c   o x i d a s e\n",
      "reply to murali et al proton translocation stoichiometry of cbb3type cytochrome c oxidase\n",
      "\n",
      "R e p l y   t o   G o e m a n   e t   a l . :   T r a d e - o f f s   i n   m o d e l   a v e r a g i n g   u s i n g   m u l t i l e v e l   t e s t s\n",
      "reply to goeman et al tradeoffs in model averaging using multilevel tests\n",
      "\n",
      "R e p l y   t o   S a s a k i   e t   a l . :   T E A D 4   i s   p r e d o m i n a n t l y   c y t o p l a s m i c   i n   t h e   i n n e r   c e l l   m a s s   o f   m o u s e   b l a s t o c y s t s\n",
      "reply to sasaki et al tead4 is predominantly cytoplasmic in the inner cell mass of mouse blastocysts\n",
      "\n",
      "A microbiota and dietary metabolite integrates DNA repair and cell death to regulate embryo viability and aneuploidy during aging\n",
      "a microbiota and dietary metabolite integrates dna repair and cell death to regulate embryo viability and aneuploidy during aging\n",
      "\n",
      "A l m o s t   a l l   h u m a n   g e n e s   r e s u l t e d   f r o m   a n c i e n t   d u p l i c a t i o n\n",
      "almost all human genes resulted from ancient duplication\n",
      "\n",
      "H y d r o l o g i c   r e g u l a t i o n   o f   p l a n t   r o o t i n g   d e p t h :   B r e a k t h r o u g h   o r   o b s e r v a t i o n a l   c o n u n d r u m ?\n",
      "hydrologic regulation of plant rooting depth breakthrough or observational conundrum\n",
      "\n",
      "The role of Northeast Pacific meltwater events in deglacial climate change\n",
      "the role of northeast pacific meltwater events in deglacial climate change\n",
      "\n",
      "R e p l y   t o   T e d e r s o o   e t   a l . :   P l a n t   s p e c i e s   w i t h i n   t h e   s a m e   f a m i l y   o r   g e n u s   c a n   h a v e   d i f f e r e n t   m y c o r r h i z a l   t y p e s ?\n",
      "reply to tedersoo et al plant species within the same family or genus can have different mycorrhizal types\n",
      "\n",
      "D e c i p h e r i n g   t h e   D e n i s o v a n s\n",
      "deciphering the denisovans\n",
      "\n",
      "R e s p o n s e   t o   C o m m e n t s   b y   Y a o l i n   L i n   a n d   W e i   Y a n g   “ D e v e l o p m e n t   o f   a   D a t a - D r i v e n   P r e d i c t i v e   M o d e l   o f   S u p p l y   A i r   T e m p e r a t u r e   i n   a n   A i r - H a n d l i n g   U n i t   f o r   C o n s e r v i n g   E n e r g y ” .   E n e r g i e s   2 0 1 8 ,   1 1 ,   4 0 7\n",
      "response to comments by yaolin lin and wei yang development of a datadriven predictive model of supply air temperature in an airhandling unit for conserving energy energies 2018 11 407\n",
      "\n",
      "R e p l y   t o   O l l i n g e r   e t   a l . :   R e m o t e   s e n s i n g   o f   l e a f   n i t r o g e n   a n d   e m e r g e n t   e c o s y s t e m   p r o p e r t i e s\n",
      "reply to ollinger et al remote sensing of leaf nitrogen and emergent ecosystem properties\n",
      "\n",
      "H o w   s o c i a l   s t a t u s   s h a p e s   r a c e\n",
      "how social status shapes race\n",
      "\n",
      "A global lightning location algorithm based on the electromagnetic signature in the Schumann resonance band\n",
      "a global lightning location algorithm based on the electromagnetic signature in the schumann resonance band\n",
      "\n",
      "R e p l y   t o   C o l u s s i :   M i c r o d r o p l e t   i n t e r f a c i a l   p H ,   t h e   o n g o i n g   d i s c u s s i o n\n",
      "reply to colussi microdroplet interfacial ph the ongoing discussion\n",
      "\n",
      "H e n r y   B o u r n e :   G   p r o t e i n   w i z a r d ,   a c a d e m i c   i n n o v a t o r ,   c o m m e n t a t o r ,   a n d   c r i t i c\n",
      "henry bourne g protein wizard academic innovator commentator and critic\n",
      "\n",
      "C o r r e c t i o n :   D i n g ,   X . ;   L i u ,   G . ;   D u ,   M . ;   G u o ,   H . ;   Q i a o ,   H .   a n d   G e r a d a ,   C .   D e v e l o p m e n t   o f   a n   A x i a l   F l u x   M E M S   B L D C   M i c r o m o t o r   w i t h   I n c r e a s e d   E f f i c i e n c y   a n d   P o w e r   D e n s i t y .   E n e r g i e s   2 0 1 5 ,   8 ,   6 6 0 8 – 6 6 2 6\n",
      "correction ding x liu g du m guo h qiao h and gerada c development of an axial flux mems bldc micromotor with increased efficiency and power density energies 2015 8 66086626\n",
      "\n",
      "W e a k   s u p p o r t   f o r   d i s a p p e a r a n c e   a n d   r e s t r i c t e d   e m e r g e n c e / p e r s i s t e n c e   o f   h i g h l y   p a t h o g e n i c   i n f l u e n z a   A   i n   N o r t h   A m e r i c a n   w a t e r f o w l\n",
      "weak support for disappearance and restricted emergencepersistence of highly pathogenic influenza a in north american waterfowl\n",
      "\n",
      "E l e m e n t a r y   i n e q u a l i t i e s   t h a t   i n v o l v e   t w o   n o n n e g a t i v e   v e c t o r s   o r   f u n c t i o n s\n",
      "elementary inequalities that involve two nonnegative vectors or functions\n",
      "\n",
      "R e p l y   t o   S k o y l e s :   M i s p l a c e d   a s s u m p t i o n s   o f   p e r f e c t   h u m a n   p r o s o c i a l i t y\n",
      "reply to skoyles misplaced assumptions of perfect human prosociality\n",
      "\n",
      "D i p s   a n d   b u m p s :   O n   B l o c h ’ s   l a w   a n d   t h e   B r o c a - S u l z e r   p h e n o m e n o n\n",
      "dips and bumps on blochs law and the brocasulzer phenomenon\n",
      "\n",
      "D o   c r o w s   r e a s o n   a b o u t   c a u s e s   o r   a g e n t s ?   T h e   d e v i l   i s   i n   t h e   c o n t r o l s\n",
      "do crows reason about causes or agents the devil is in the controls\n",
      "\n",
      "A n   a n c e s t r a l   a n a t o m i c a l   a n d   s p a t i a l   b i a s   f o r   v i s u a l l y   g u i d e d   b e h a v i o r\n",
      "an ancestral anatomical and spatial bias for visually guided behavior\n",
      "\n",
      "M o d e l i n g   F o r e s t   S t a n d   D y n a m i c s ,   G r o w t h   a n d   Y i e l d\n",
      "modeling forest stand dynamics growth and yield\n",
      "\n",
      "R o l e   f o r   t e r m i n a l   c o m p l e m e n t   a c t i v a t i o n   i n   a m y o t r o p h i c   l a t e r a l   s c l e r o s i s   d i s e a s e   p r o g r e s s i o n\n",
      "role for terminal complement activation in amyotrophic lateral sclerosis disease progression\n",
      "\n",
      "EDITORIALAMS Policy on Plagiarism and Self-Plagiarism\n",
      "editorialams policy on plagiarism and selfplagiarism\n",
      "\n",
      "S h o u l d   S o c i a l   S e c u r i t y   n u m b e r s   b e   r e p l a c e d   b y   m o d e r n ,   m o r e   s e c u r e   i d e n t i f i e r s ?\n",
      "should social security numbers be replaced by modern more secure identifiers\n",
      "\n",
      "R e p l y   t o   M a r g a l i d a   a n d   C o l o m e r :   S c i e n c e   s h o u l d   s t r i v e   t o   p r e v e n t   m i s t a k e s ,   n o t   c o r r e c t i o n s\n",
      "reply to margalida and colomer science should strive to prevent mistakes not corrections\n",
      "\n",
      "R e p l y   t o   G ö r n e r   e t   a l . :   E n c o d i n g   g a z e   a s   i m p l i e d   m o t i o n\n",
      "reply to görner et al encoding gaze as implied motion\n",
      "\n",
      "R e p l y   t o   S l e s a k   e t   a l . :   S o   m u c h   a b o u t   R i c k e t t s i a   f e l i s   i n f e c t i o n   t o   b e   d i s c o v e r e d\n",
      "reply to slesak et al so much about rickettsia felis infection to be discovered\n",
      "\n",
      "How green can Amazon hydropower be? Net carbon emission from the largest hydropower plant in Amazonia\n",
      "how green can amazon hydropower be net carbon emission from the largest hydropower plant in amazonia\n",
      "\n",
      "R e p l y   t o   B a u e r   e t   a l . :   M u r i n e   p D C   r e c o g n i t i o n   o f   v a c c i n i a   v i r a l   D N A   i s   m e d i a t e d   b y   T L R 8\n",
      "reply to bauer et al murine pdc recognition of vaccinia viral dna is mediated by tlr8\n",
      "\n",
      "R e p l y   t o   T e r h u n e   a n d   J a m i e s o n :   T h e   n a t u r e   o f   a b s o r p t i o n\n",
      "reply to terhune and jamieson the nature of absorption\n",
      "\n",
      "N o   e v i d e n c e   o f   c r y p t i c   b y c a t c h   c a u s i n g   N e w   Z e a l a n d   s e a   l i o n   p o p u l a t i o n   d e c l i n e\n",
      "no evidence of cryptic bycatch causing new zealand sea lion population decline\n",
      "\n",
      "Long-term rise in riverine dissolved organic carbon concentration is predicted by electrolyte solubility theory\n",
      "longterm rise in riverine dissolved organic carbon concentration is predicted by electrolyte solubility theory\n",
      "\n",
      "Dependence of regional ocean heat uptake on anthropogenic warming scenarios\n",
      "dependence of regional ocean heat uptake on anthropogenic warming scenarios\n",
      "\n",
      "R e p l y   t o   H o r t a l   e t   a l . :   P a t t e r n s   o f   b i r d   d i s t r i b u t i o n   i n   S p a i n   s u p p o r t   t h e   a r e a – h e t e r o g e n e i t y   t r a d e o f f\n",
      "reply to hortal et al patterns of bird distribution in spain support the areaheterogeneity tradeoff\n",
      "\n",
      "D o n ’ t   w a s t e   g o o d   m e t h o d s   o n   b a d   b u f f e r s   a n d   a m b i g u o u s   d a t a\n",
      "dont waste good methods on bad buffers and ambiguous data\n",
      "\n",
      "R e p l y   t o   J a c o b s   a n d   M a n f r e d o :   M o r e   s u p p o r t   f o r   a   p e r v a s i v e   d e c l i n e   i n   n a t u r e - b a s e d   r e c r e a t i o n\n",
      "reply to jacobs and manfredo more support for a pervasive decline in naturebased recreation\n",
      "\n",
      "G o l d e n   R u l e   o r   v a l e n c e   m a t c h i n g ?   M e t h o d o l o g i c a l   p r o b l e m s   i n   H a m l i n   e t   a l .\n",
      "golden rule or valence matching methodological problems in hamlin et al\n",
      "\n",
      "N o   e v i d e n c e   f o r   s a m p l e   c o n t a m i n a t i o n   o r   d i e t   o f f s e t   f o r   p r e - C o l u m b i a n   c h i c k e n   d a t e s   f r o m   E l   A r e n a l\n",
      "no evidence for sample contamination or diet offset for precolumbian chicken dates from el arenal\n",
      "\n",
      "Speleothem record of mild and wet mid-Pleistocene climate in northeast Greenland\n",
      "speleothem record of mild and wet midpleistocene climate in northeast greenland\n",
      "\n",
      "R e p l y   t o   D r u r y   a n d   T h e a l l :   N o   e v i d e n c e   o f   p o p u l a t i o n   s t r a t i f i c a t i o n\n",
      "reply to drury and theall no evidence of population stratification\n",
      "\n",
      "R e p l y   t o   W a g e r   e t   a l . :   P a i n   a n d   t h e   d A C C :   T h e   i m p o r t a n c e   o f   h i t   r a t e - a d j u s t e d   e f f e c t s   a n d   p o s t e r i o r   p r o b a b i l i t i e s   w i t h   f a i r   p r i o r s\n",
      "reply to wager et al pain and the dacc the importance of hit rateadjusted effects and posterior probabilities with fair priors\n",
      "\n",
      "C l a s s i f y i n g   m o b i l e   g e n e t i c   e l e m e n t s   a n d   t h e i r   i n t e r a c t i o n s   f r o m   s e q u e n c e   d a t a :   T h e   i m p o r t a n c e   o f   e x i s t i n g   b i o l o g i c a l   k n o w l e d g e\n",
      "classifying mobile genetic elements and their interactions from sequence data the importance of existing biological knowledge\n",
      "\n",
      "M u l t i m e s s e n g e r   a s t r o n o m y   p r o b e s   d e e p - s p a c e   e v e n t s   w i t h   a n   a r s e n a l   o f   l e n s e s\n",
      "multimessenger astronomy probes deepspace events with an arsenal of lenses\n",
      "\n",
      "A t m o s p h e r i c   a n d   O c e a n   O p t i c s :   A t m o s p h e r i c   P h y s i c s   I I\n",
      "atmospheric and ocean optics atmospheric physics ii\n",
      "\n",
      "A   m o r e   p r e c i s e   l o o k   a t   c o n t e x t   i n   a u t i s m\n",
      "a more precise look at context in autism\n",
      "\n",
      "C o a s t a l   m a r i n e   e u t r o p h i c a t i o n :   C o n t r o l   o f   b o t h   n i t r o g e n   a n d   p h o s p h o r u s   i s   n e c e s s a r y\n",
      "coastal marine eutrophication control of both nitrogen and phosphorus is necessary\n",
      "\n",
      "R e p l y   t o   B e l l   e t   a l . :   N r f 2 - d e p e n d e n t   a n d   - i n d e p e n d e n t   m e c h a n i s m s   o f   a s t r o c y t i c   n e u r o p r o t e c t i o n\n",
      "reply to bell et al nrf2dependent and independent mechanisms of astrocytic neuroprotection\n",
      "\n",
      "A   j u s t i c e   s y s t e m   t h a t   d e n i e s   f r e e   w i l l   i s   n o t   b a s e d   o n   j u s t i c e\n",
      "a justice system that denies free will is not based on justice\n",
      "\n",
      "C o r r e c t i o n :   D e l l a S a l a ,   D . A . ,   e t   a l .   B u i l d i n g   o n   T w o   D e c a d e s   o f   E c o s y s t e m   M a n a g e m e n t   a n d   B i o d i v e r s i t y   C o n s e r v a t i o n   u n d e r   t h e   N o r t h w e s t   F o r e s t   P l a n ,   U S A .   F o r e s t s ,   2 0 1 5 ,   6 ,   3 3 2 6\n",
      "correction dellasala da et al building on two decades of ecosystem management and biodiversity conservation under the northwest forest plan usa forests 2015 6 3326\n",
      "\n",
      "E r g o d i c i t y   i s   s u f f i c i e n t   b u t   n o t   n e c e s s a r y   f o r   g r o u p - t o - i n d i v i d u a l   g e n e r a l i z a b i l i t y\n",
      "ergodicity is sufficient but not necessary for grouptoindividual generalizability\n",
      "\n",
      "A   F o r e s t   S e r v i c e   V i s i o n   d u r i n g   t h e   A n t h r o p o c e n e\n",
      "a forest service vision during the anthropocene\n",
      "\n",
      "A   n e w   a p p r o a c h   t o   f i n a n c i a l   r e g u l a t i o n\n",
      "a new approach to financial regulation\n",
      "\n",
      "W a v e - S t r u c t u r e   I n t e r a c t i o n   P r o c e s s e s   i n   C o a s t a l   E n g i n e e r i n g\n",
      "wavestructure interaction processes in coastal engineering\n",
      "\n",
      "U s i n g   s e l e c t i o n   b i a s   t o   e x p l a i n   t h e   o b s e r v e d   s t r u c t u r e   o f   I n t e r n e t   d i f f u s i o n s\n",
      "using selection bias to explain the observed structure of internet diffusions\n",
      "\n",
      "A   p r o m i s i n g   f r o n t   i n   t h e   w a r   o n   i n e q u a l i t y\n",
      "a promising front in the war on inequality\n",
      "\n",
      "E f f e c t   o f   L o a d   C h a n g e   o n   t h e   T h e v e n i n   E q u i v a l e n t   I m p e d a n c e   o f   P o w e r   S y s t e m\n",
      "effect of load change on the thevenin equivalent impedance of power system\n",
      "\n",
      "T a n d e m   d u p l i c a t i o n s   c o n t r i b u t e   t o   n o t   o n e   b u t   t w o   d i s t i n c t   p h e n o t y p e s\n",
      "tandem duplications contribute to not one but two distinct phenotypes\n",
      "\n",
      "N a t u r e - B a s e d   S o l u t i o n s   f o r   t h e   M i t i g a t i o n   o f   P e r s i s t e n t   a n d   E m e r g i n g   C o n t a m i n a n t s\n",
      "naturebased solutions for the mitigation of persistent and emerging contaminants\n",
      "\n",
      "R e c e n t   e v i d e n c e   f o r   p e r v a s i v e   a d a p t a t i o n   t a r g e t i n g   g e n e   e x p r e s s i o n   a t t r i b u t a b l e   t o   p o p u l a t i o n   s i z e   c h a n g e\n",
      "recent evidence for pervasive adaptation targeting gene expression attributable to population size change\n",
      "\n",
      "D o n ’ t   t r y   t o   c o n v e r t   t h e   a n t i v a c c i n a t o r s ,   i n s t e a d   t a r g e t   t h e   f e n c e - s i t t e r s\n",
      "dont try to convert the antivaccinators instead target the fencesitters\n",
      "\n",
      "R e p l y   t o   P a r k e r :   R o b u s t   r e s p o n s e   o f   A M O C   i n t e r d e c a d a l   v a r i a b i l i t y   t o   f u t u r e   i n t e n s e   w a r m i n g\n",
      "reply to parker robust response of amoc interdecadal variability to future intense warming\n",
      "\n",
      "Energy provision and housing development: Re-thinking professional and technological relations\n",
      "energy provision and housing development rethinking professional and technological relations\n",
      "\n",
      "B i o d i v e r s i t y   a n d   e c o s y s t e m   f u n c t i o n i n g :   E f f e c t s   o f   t h e   l o s s   o f   s a l a m a n d e r   s p e c i e s   r i c h n e s s\n",
      "biodiversity and ecosystem functioning effects of the loss of salamander species richness\n",
      "\n",
      "R e t r o s p e c t i v e   o f   C h a r l e s   P e n c e   S l i c h t e r   ( N A S   1 9 6 7 )\n",
      "retrospective of charles pence slichter nas 1967\n",
      "\n",
      "R e p l y   t o   B e s t   a n d   A s h b y :   T h e   c o n c e p t   o f   e v o l u t i o n a r i l y   s t a b l e   s t r a t e g i e s   ( E S S )   h e l p s   l i n k   e c o l o g y   a n d   e v o l u t i o n\n",
      "reply to best and ashby the concept of evolutionarily stable strategies ess helps link ecology and evolution\n",
      "\n",
      "A n   I n n o v a t i v e   A p p r o a c h   t o   C l e a n i n g   U p   O r g a n i c   a n d   I n o r g a n i c   C o n t a m i n a t i o n s   f r o m   S o i l   a n d   W a t e r\n",
      "an innovative approach to cleaning up organic and inorganic contaminations from soil and water\n",
      "\n",
      "P r o f i l e   o f   J a n e t   H e m i n g w a y\n",
      "profile of janet hemingway\n",
      "\n",
      "S i m i a n   v i r u s   4 0   a n d   t h e   h u m a n   m e s o t h e l i u m\n",
      "simian virus 40 and the human mesothelium\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = df_lists_only[df_lists_only.num_references <= 10].sample(100)[\"Title\"].to_list()\n",
    "\n",
    "def fix_title(title):\n",
    "    \"\"\"\n",
    "    Normalizes a paper title string, using a simple rule to detect spaced-out text.\n",
    "\n",
    "    The logic is:\n",
    "    1. Check if the title contains a double-space (\"  \").\n",
    "    2. IF IT DOES: Assume it's \"spaced-out\" text (e.g., \"T i t l e   W o r d\").\n",
    "       - Mark the real word breaks (the double-spaces) with a placeholder.\n",
    "       - Remove all single spaces (the junk between letters).\n",
    "       - Restore the real word breaks.\n",
    "    3. IF IT DOES NOT: Treat it as a normal title.\n",
    "    4. Finally, apply standard cleaning (lowercase, remove punctuation, etc.) to all titles.\n",
    "\n",
    "    Args:\n",
    "        title (str or any): The input title to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized title string. Returns an empty string if input is not a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "\n",
    "    if \"  \" in title:\n",
    "        placeholder = \"@@@\"\n",
    "        \n",
    "        title_fixed = re.sub(r'\\s{2,}', placeholder, title)\n",
    "        \n",
    "        title_fixed = title_fixed.replace(' ', '')\n",
    "        \n",
    "        title = title_fixed.replace(placeholder, ' ')\n",
    "        \n",
    "    title = title.lower()\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    title = \" \".join(title.split())\n",
    "    \n",
    "    return title\n",
    "\n",
    "for title in a:\n",
    "    print(title)\n",
    "    print(fix_title(title))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bd00ec",
   "metadata": {},
   "source": [
    "This function seems to be working for titles, next, reference titles should be tackled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34a57f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title_from_reference(ref_string):\n",
    "    \"\"\"\n",
    "    Extracts the most likely title from a scientific reference string.\n",
    "\n",
    "    This uses a simple but robust heuristic:\n",
    "    1. Removes bracketed metadata (e.g., [CrossRef]).\n",
    "    2. Splits the reference by periods ('.').\n",
    "    3. Assumes the longest resulting segment is the title.\n",
    "\n",
    "    Args:\n",
    "        ref_string (str): The reference string to parse.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted title, or None if no suitable title is found.\n",
    "    \"\"\"\n",
    "    if not isinstance(ref_string, str):\n",
    "        return None\n",
    "\n",
    "    # 1. Pre-clean: Remove bracketed metadata like [Google Scholar] [CrossRef]\n",
    "    cleaned_ref = re.sub(r'\\[.*?\\]', '', ref_string).strip()\n",
    "    \n",
    "    # 2. Split the string into major parts using the period as a delimiter\n",
    "    parts = cleaned_ref.split('.')\n",
    "    \n",
    "    # 3. Filter out empty or very short parts that can't be titles\n",
    "    # A title usually has some substance. We also strip whitespace from each part.\n",
    "    potential_titles = [part.strip() for part in parts if len(part.strip()) > 10]\n",
    "    \n",
    "    # If, after filtering, there are no candidates, we can't find a title\n",
    "    if not potential_titles:\n",
    "        return None\n",
    "        \n",
    "    # 4. Select the longest part from the candidates\n",
    "    # The title is almost always the longest meaningful segment of a reference.\n",
    "    title = max(potential_titles, key=len)\n",
    "    \n",
    "    return title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be215cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref in df_lists_only[df_lists_only.num_references <= 100].sample(1)[\"References\"].to_list()[0]:\n",
    "    print(ref)\n",
    "    print(extract_title_from_reference(ref))\n",
    "    print(fix_title(extract_title_from_reference(ref)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57185bd",
   "metadata": {},
   "source": [
    "This setup seems to work good for references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dee75a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "May 17, 2004\n",
      "2004\n",
      "\n",
      "May 1, 2012\n",
      "2012\n",
      "\n",
      "\n",
      "Received: 1 June 2017\n",
      "/\n",
      "Revised: 13 June 2017\n",
      "/\n",
      "Accepted: 14 June 2017\n",
      "/\n",
      "Published: 17 June 2017\n",
      "\n",
      "2017\n",
      "\n",
      "2022-07-01\n",
      "2022\n",
      "\n",
      "\n",
      "Received: 1 July 2023\n",
      "/\n",
      "Revised: 4 August 2023\n",
      "/\n",
      "Accepted: 5 August 2023\n",
      "/\n",
      "Published: 8 August 2023\n",
      "\n",
      "2023\n",
      "\n",
      "2011\n",
      "2011\n",
      "\n",
      "February 4, 2013\n",
      "2013\n",
      "\n",
      "February 19, 2002\n",
      "2002\n",
      "\n",
      "November 13, 2001\n",
      "2001\n",
      "\n",
      "\n",
      "Received: 18 May 2022\n",
      "/\n",
      "Revised: 1 July 2022\n",
      "/\n",
      "Accepted: 6 July 2022\n",
      "/\n",
      "Published: 11 July 2022\n",
      "\n",
      "2022\n",
      "\n",
      "July 22, 2022\n",
      "2022\n",
      "\n",
      "December 23, 2013\n",
      "2013\n",
      "\n",
      "February 17, 2009\n",
      "2009\n",
      "\n",
      "2019\n",
      "2019\n",
      "\n",
      "\n",
      "Received: 18 October 2021\n",
      "/\n",
      "Revised: 12 November 2021\n",
      "/\n",
      "Accepted: 6 December 2021\n",
      "/\n",
      "Published: 13 December 2021\n",
      "\n",
      "2021\n",
      "\n",
      "\n",
      "Received: 11 May 2018\n",
      "/\n",
      "Revised: 11 July 2018\n",
      "/\n",
      "Accepted: 18 July 2018\n",
      "/\n",
      "Published: 25 July 2018\n",
      "\n",
      "2018\n",
      "\n",
      "\n",
      "Received: 22 March 2023\n",
      "/\n",
      "Revised: 9 April 2023\n",
      "/\n",
      "Accepted: 13 April 2023\n",
      "/\n",
      "Published: 14 April 2023\n",
      "\n",
      "2023\n",
      "\n",
      "\n",
      "Received: 8 July 2019\n",
      "/\n",
      "Revised: 25 July 2019\n",
      "/\n",
      "Accepted: 25 July 2019\n",
      "/\n",
      "Published: 28 July 2019\n",
      "\n",
      "2019\n",
      "\n",
      "June 18, 2013\n",
      "2013\n",
      "\n",
      "July 8, 2013\n",
      "2013\n",
      "\n",
      "\n",
      "Received: 21 August 2020\n",
      "/\n",
      "Revised: 7 September 2020\n",
      "/\n",
      "Accepted: 9 September 2020\n",
      "/\n",
      "Published: 11 September 2020\n",
      "\n",
      "2020\n",
      "\n",
      "October 29, 2014\n",
      "2014\n",
      "\n",
      "August 1, 2006\n",
      "2006\n",
      "\n",
      "December 13, 2021\n",
      "2021\n",
      "\n",
      "November 24, 2021\n",
      "2021\n",
      "\n",
      "\n",
      "Received: 16 January 2020\n",
      "/\n",
      "Accepted: 16 January 2020\n",
      "/\n",
      "Published: 9 March 2020\n",
      "\n",
      "2020\n",
      "\n",
      "2015\n",
      "2015\n",
      "\n",
      "\n",
      "Received: 30 November 2020\n",
      "/\n",
      "Revised: 15 December 2020\n",
      "/\n",
      "Accepted: 17 December 2020\n",
      "/\n",
      "Published: 21 December 2020\n",
      "\n",
      "2020\n",
      "\n",
      "September 24, 2004\n",
      "2004\n",
      "\n",
      "June 13, 2006\n",
      "2006\n",
      "\n",
      "August 30, 2012\n",
      "2012\n",
      "\n",
      "2017\n",
      "2017\n",
      "\n",
      "February 23, 2010\n",
      "2010\n",
      "\n",
      "June 14, 2022\n",
      "2022\n",
      "\n",
      "January 6, 2003\n",
      "2003\n",
      "\n",
      "\n",
      "Received: 6 January 2015\n",
      "/\n",
      "Revised: 15 February 2015\n",
      "/\n",
      "Accepted: 16 February 2015\n",
      "/\n",
      "Published: 27 February 2015\n",
      "\n",
      "2015\n",
      "\n",
      "\n",
      "Received: 1 August 2022\n",
      "/\n",
      "Revised: 31 August 2022\n",
      "/\n",
      "Accepted: 19 September 2022\n",
      "/\n",
      "Published: 22 September 2022\n",
      "\n",
      "2022\n",
      "\n",
      "October 21, 2002\n",
      "2002\n",
      "\n",
      "2006\n",
      "2006\n",
      "\n",
      "December 16, 2008\n",
      "2008\n",
      "\n",
      "2016\n",
      "2016\n",
      "\n",
      "2022\n",
      "2022\n",
      "\n",
      "April 10, 2023\n",
      "2023\n",
      "\n",
      "February 22, 2016\n",
      "2016\n",
      "\n",
      "October 18, 2005\n",
      "2005\n",
      "\n",
      "\n",
      "Received: 16 October 2019\n",
      "/\n",
      "Revised: 8 November 2019\n",
      "/\n",
      "Accepted: 7 December 2019\n",
      "/\n",
      "Published: 10 December 2019\n",
      "\n",
      "2019\n",
      "\n",
      "\n",
      "Received: 15 June 2021\n",
      "/\n",
      "Revised: 19 July 2021\n",
      "/\n",
      "Accepted: 27 July 2021\n",
      "/\n",
      "Published: 30 July 2021\n",
      "\n",
      "2021\n",
      "\n",
      "\n",
      "Received: 25 March 2023\n",
      "/\n",
      "Revised: 3 May 2023\n",
      "/\n",
      "Accepted: 15 May 2023\n",
      "/\n",
      "Published: 23 May 2023\n",
      "\n",
      "2023\n",
      "\n",
      "May 27, 2010\n",
      "2010\n",
      "\n",
      "May 14, 2002\n",
      "2002\n",
      "\n",
      "January 9, 2007\n",
      "2007\n",
      "\n",
      "June 20, 2023\n",
      "2023\n",
      "\n",
      "April 14, 2005\n",
      "2005\n",
      "\n",
      "April 12, 2010\n",
      "2010\n",
      "\n",
      "March 1, 2021\n",
      "2021\n",
      "\n",
      "\n",
      "Received: 12 August 2021\n",
      "/\n",
      "Revised: 31 August 2021\n",
      "/\n",
      "Accepted: 15 September 2021\n",
      "/\n",
      "Published: 17 September 2021\n",
      "\n",
      "2021\n",
      "\n",
      "2019\n",
      "2019\n",
      "\n",
      "July 18, 2011\n",
      "2011\n",
      "\n",
      "March 10, 2017\n",
      "2017\n",
      "\n",
      "October 2, 2023\n",
      "2023\n",
      "\n",
      "February 8, 2023\n",
      "2023\n",
      "\n",
      "August 15, 2000\n",
      "2000\n",
      "\n",
      "April 6, 2020\n",
      "2020\n",
      "\n",
      "May 21, 2002\n",
      "2002\n",
      "\n",
      "February 6, 2019\n",
      "2019\n",
      "\n",
      "June 10, 2004\n",
      "2004\n",
      "\n",
      "August 22, 2016\n",
      "2016\n",
      "\n",
      "\n",
      "Received: 8 December 2022\n",
      "/\n",
      "Revised: 28 December 2022\n",
      "/\n",
      "Accepted: 30 December 2022\n",
      "/\n",
      "Published: 9 January 2023\n",
      "\n",
      "2023\n",
      "\n",
      "\n",
      "Received: 8 September 2022\n",
      "/\n",
      "Revised: 10 October 2022\n",
      "/\n",
      "Accepted: 18 October 2022\n",
      "/\n",
      "Published: 20 October 2022\n",
      "\n",
      "2022\n",
      "\n",
      "December 1, 2003\n",
      "2003\n",
      "\n",
      "\n",
      "Received: 11 July 2023\n",
      "/\n",
      "Revised: 8 August 2023\n",
      "/\n",
      "Accepted: 9 August 2023\n",
      "/\n",
      "Published: 11 August 2023\n",
      "\n",
      "2023\n",
      "\n",
      "March 2, 2015\n",
      "2015\n",
      "\n",
      "June 30, 2009\n",
      "2009\n",
      "\n",
      "2016\n",
      "2016\n",
      "\n",
      "September 6, 2016\n",
      "2016\n",
      "\n",
      "July 25, 2000\n",
      "2000\n",
      "\n",
      "2015\n",
      "2015\n",
      "\n",
      "\n",
      "Received: 30 August 2018\n",
      "/\n",
      "Revised: 30 October 2018\n",
      "/\n",
      "Accepted: 5 November 2018\n",
      "/\n",
      "Published: 9 November 2018\n",
      "\n",
      "2018\n",
      "\n",
      "December 19, 2000\n",
      "2000\n",
      "\n",
      "2008\n",
      "2008\n",
      "\n",
      "August 24, 2015\n",
      "2015\n",
      "\n",
      "May 12, 2009\n",
      "2009\n",
      "\n",
      "\n",
      "Received: 5 March 2022\n",
      "/\n",
      "Revised: 17 March 2022\n",
      "/\n",
      "Accepted: 18 March 2022\n",
      "/\n",
      "Published: 30 March 2022\n",
      "\n",
      "2022\n",
      "\n",
      "\n",
      "Received: 22 August 2023\n",
      "/\n",
      "Revised: 4 October 2023\n",
      "/\n",
      "Accepted: 5 October 2023\n",
      "/\n",
      "Published: 8 October 2023\n",
      "\n",
      "2023\n",
      "\n",
      "March 22, 2016\n",
      "2016\n",
      "\n",
      "\n",
      "Received: 28 September 2020\n",
      "/\n",
      "Revised: 1 December 2020\n",
      "/\n",
      "Accepted: 8 December 2020\n",
      "/\n",
      "Published: 10 December 2020\n",
      "\n",
      "2020\n",
      "\n",
      "April 4, 2011\n",
      "2011\n",
      "\n",
      "August 15, 2000\n",
      "2000\n",
      "\n",
      "2019\n",
      "2019\n",
      "\n",
      "March 7, 2003\n",
      "2003\n",
      "\n",
      "December 2, 2013\n",
      "2013\n",
      "\n",
      "July 3, 2019\n",
      "2019\n",
      "\n",
      "\n",
      "Received: 18 January 2023\n",
      "/\n",
      "Revised: 22 February 2023\n",
      "/\n",
      "Accepted: 28 February 2023\n",
      "/\n",
      "Published: 2 March 2023\n",
      "\n",
      "2023\n",
      "\n",
      "\n",
      "Received: 27 May 2020\n",
      "/\n",
      "Revised: 30 June 2020\n",
      "/\n",
      "Accepted: 2 July 2020\n",
      "/\n",
      "Published: 7 July 2020\n",
      "\n",
      "2020\n",
      "\n",
      "2007\n",
      "2007\n",
      "\n",
      "2013\n",
      "2013\n",
      "\n",
      "September 9, 2019\n",
      "2019\n",
      "\n",
      "2021\n",
      "2021\n",
      "\n",
      "\n",
      "Received: 30 August 2018\n",
      "/\n",
      "Revised: 14 October 2018\n",
      "/\n",
      "Accepted: 15 October 2018\n",
      "/\n",
      "Published: 9 January 2019\n",
      "\n",
      "2019\n",
      "\n",
      "\n",
      "Received: 1 September 2023\n",
      "/\n",
      "Revised: 2 October 2023\n",
      "/\n",
      "Accepted: 6 October 2023\n",
      "/\n",
      "Published: 9 October 2023\n",
      "\n",
      "2023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_year(date_string):\n",
    "    \"\"\"\n",
    "    Extracts the most likely publication year from a messy date string.\n",
    "\n",
    "    This function tries several strategies in order:\n",
    "    1. Looks for a year in a \"Published: ...\" line.\n",
    "    2. If not found, it searches for any four-digit number starting with 19 or 20.\n",
    "    3. Returns the last year found in the string, as 'Published' is usually last.\n",
    "\n",
    "    Args:\n",
    "        date_string (str): The messy string from the 'Date' column.\n",
    "\n",
    "    Returns:\n",
    "        int or None: The extracted four-digit year as an integer, or None if no\n",
    "                     plausible year can be found.\n",
    "    \"\"\"\n",
    "    if not isinstance(date_string, str):\n",
    "        return None\n",
    "\n",
    "    published_match = re.search(r'Published: .*?(\\b(19|20)\\d{2}\\b)', date_string)\n",
    "    if published_match:\n",
    "        return int(published_match.group(1))\n",
    "\n",
    "    all_years = re.findall(r'\\b(?:19|20)\\d{2}\\b', date_string)\n",
    "    \n",
    "    if all_years:\n",
    "        return int(all_years[-1])\n",
    "\n",
    "    # If no year could be found, return None\n",
    "    return \"no_date\"\n",
    "\n",
    "for date in df_lists_only.Date.sample(100).tolist():\n",
    "    print(date)\n",
    "    print(extract_year(date))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6cca6",
   "metadata": {},
   "source": [
    "## 2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4bde7efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the corpus...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0028650760650634766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Normalizing Titles",
       "rate": null,
       "total": 156237,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a51ed3e8c254f7da92bf1c96313feaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing Titles:   0%|          | 0/156237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9296/2792831858.py:120: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['normalized_title'] = df['Title'].progress_apply(fix_title)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002548694610595703,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting Years",
       "rate": null,
       "total": 156237,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc5096fe939435a8fbd824bb6e54cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Years:   0%|          | 0/156237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating title-to-index map...\n",
      "\n",
      "Starting the reference linking process...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9296/2792831858.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['year'] = df['Date'].progress_apply(extract_year)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0028829574584960938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Linking Documents",
       "rate": null,
       "total": 156237,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bc43c694114dfda534e9eeb2a8a8bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Linking Documents:   0%|          | 0/156237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 152\u001b[0m\n\u001b[1;32m    149\u001b[0m ref_year \u001b[38;5;241m=\u001b[39m extract_year(ref_string)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Find the best match in the entire corpus\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m matched_title, target_index, score \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_match_for_reference_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_ref_title\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcorpus_titles_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_year\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mref_year\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m85\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# You can tune this!\u001b[39;49;00m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43myear_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m    159\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# If a good match was found, store it\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[148], line 105\u001b[0m, in \u001b[0;36mfind_best_match_for_reference_v2\u001b[0;34m(ref_title, corpus_df, titles_map, ref_year, threshold, year_tol)\u001b[0m\n\u001b[1;32m    102\u001b[0m candidate_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(candidate_corpus\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m candidate_titles: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m best_match \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractOne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_titles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuzz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_match:\n\u001b[1;32m    108\u001b[0m     matched_title_str, score, original_list_index \u001b[38;5;241m=\u001b[39m best_match\n",
      "File \u001b[0;32msrc/rapidfuzz/process_cpp_impl.pyx:848\u001b[0m, in \u001b[0;36mrapidfuzz.process_cpp_impl.extractOne\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/rapidfuzz/process_cpp_impl.pyx:718\u001b[0m, in \u001b[0;36mrapidfuzz.process_cpp_impl.extractOne_list\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/rapidfuzz/process_cpp_impl.pyx:535\u001b[0m, in \u001b[0;36mrapidfuzz.process_cpp_impl.extractOne_list_f64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz, process\n",
    "from tqdm.auto import tqdm # For a nice progress bar!\n",
    "\n",
    "\n",
    "def fix_title(title):\n",
    "    \"\"\"\n",
    "    Normalizes a paper title string, using a simple rule to detect spaced-out text.\n",
    "    Args:\n",
    "        title (str or any): The input title to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized title string. Returns an empty string if input is not a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "\n",
    "    if \"  \" in title:\n",
    "        placeholder = \"@@@\"\n",
    "        \n",
    "        title_fixed = re.sub(r'\\s{2,}', placeholder, title)\n",
    "        \n",
    "        title_fixed = title_fixed.replace(' ', '')\n",
    "        \n",
    "        title = title_fixed.replace(placeholder, ' ')\n",
    "        \n",
    "    title = title.lower()\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    title = \" \".join(title.split())\n",
    "    \n",
    "    return title\n",
    "\n",
    "def extract_title_from_reference(ref_string):\n",
    "    \"\"\"\n",
    "    Extracts the most likely title from a scientific reference string.\n",
    "    Args:\n",
    "        ref_string (str): The reference string to parse.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted title, or None if no suitable title is found.\n",
    "    \"\"\"\n",
    "    if not isinstance(ref_string, str):\n",
    "        return None\n",
    "\n",
    "    # 1. Pre-clean: Remove bracketed metadata like [Google Scholar] [CrossRef]\n",
    "    cleaned_ref = re.sub(r'\\[.*?\\]', '', ref_string).strip()\n",
    "    \n",
    "    # 2. Split the string into major parts using the period as a delimiter\n",
    "    parts = cleaned_ref.split('.')\n",
    "    \n",
    "    # 3. Filter out empty or very short parts that can't be titles\n",
    "    # A title usually has some substance. We also strip whitespace from each part.\n",
    "    potential_titles = [part.strip() for part in parts if len(part.strip()) > 10]\n",
    "    \n",
    "    # If, after filtering, there are no candidates, we can't find a title\n",
    "    if not potential_titles:\n",
    "        return None\n",
    "        \n",
    "    # 4. Select the longest part from the candidates\n",
    "    # The title is almost always the longest meaningful segment of a reference.\n",
    "    title = max(potential_titles, key=len)\n",
    "    \n",
    "    return title\n",
    "\n",
    "def extract_year(date_string):\n",
    "    \"\"\"\n",
    "    Extracts the most likely publication year from a messy date string.\n",
    "    Args:\n",
    "        date_string (str): The messy string from the 'Date' column.\n",
    "\n",
    "    Returns:\n",
    "        int or None: The extracted four-digit year as an integer, or None if no\n",
    "                     plausible year can be found.\n",
    "    \"\"\"\n",
    "    if not isinstance(date_string, str):\n",
    "        return None\n",
    "\n",
    "    published_match = re.search(r'Published: .*?(\\b(19|20)\\d{2}\\b)', date_string)\n",
    "    if published_match:\n",
    "        return int(published_match.group(1))\n",
    "\n",
    "    all_years = re.findall(r'\\b(?:19|20)\\d{2}\\b', date_string)\n",
    "    \n",
    "    if all_years:\n",
    "        return int(all_years[-1])\n",
    "\n",
    "    # If no year could be found, return None\n",
    "    return \"no_date\"\n",
    "\n",
    "def find_best_match_for_reference_v2(ref_title, corpus_df, titles_map, ref_year=None, threshold=85, year_tol=5):\n",
    "    if not ref_title: return None, None, None\n",
    "    if ref_title in titles_map: return ref_title, titles_map[ref_title], 100\n",
    "    \n",
    "    candidate_corpus = corpus_df\n",
    "    if ref_year is not None and 'year' in corpus_df.columns and pd.api.types.is_numeric_dtype(corpus_df['year']):\n",
    "        filtered_view = corpus_df[corpus_df['year'].between(ref_year - year_tol, ref_year + year_tol)]\n",
    "        if not filtered_view.empty: candidate_corpus = filtered_view\n",
    "            \n",
    "    candidate_titles = list(candidate_corpus['normalized_title'])\n",
    "    candidate_indices = list(candidate_corpus.index)\n",
    "    if not candidate_titles: return None, None, None\n",
    "\n",
    "    best_match = process.extractOne(ref_title, candidate_titles, scorer=fuzz.WRatio, score_cutoff=threshold)\n",
    "\n",
    "    if best_match:\n",
    "        matched_title_str, score, original_list_index = best_match\n",
    "        corpus_idx = candidate_indices[original_list_index]\n",
    "        return matched_title_str, corpus_idx, score\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "df = df_lists_only[df_lists_only.num_references <= 100] # Use your actual DataFrame here\n",
    "\n",
    "print(\"Preparing the corpus...\")\n",
    "# Use tqdm to see progress on large dataframes\n",
    "tqdm.pandas(desc=\"Normalizing Titles\")\n",
    "df['normalized_title'] = df['Title'].progress_apply(fix_title)\n",
    "\n",
    "tqdm.pandas(desc=\"Extracting Years\")\n",
    "df['year'] = df['Date'].progress_apply(extract_year)\n",
    "\n",
    "# Create the fast lookup map for exact matches\n",
    "print(\"Creating title-to-index map...\")\n",
    "corpus_titles_map = {title: idx for idx, title in df['normalized_title'].items() if title}\n",
    "\n",
    "\n",
    "# --- Step 3: The Main Linking Loop ---\n",
    "\n",
    "print(\"\\nStarting the reference linking process...\")\n",
    "citation_links = []\n",
    "# We iterate through each row of the DataFrame\n",
    "for source_index, row in tqdm(df.iterrows(), total=len(df), desc=\"Linking Documents\"):\n",
    "    references = row['References']\n",
    "    source_title = row['Title']\n",
    "    \n",
    "    # Ensure references is a list of strings\n",
    "    if not isinstance(references, list):\n",
    "        continue\n",
    "\n",
    "    for ref_string in references:\n",
    "        # Extract and normalize title from the reference string\n",
    "        raw_ref_title = extract_title_from_reference(ref_string)\n",
    "        norm_ref_title = fix_title(raw_ref_title)\n",
    "        \n",
    "        # Extract year from the reference string\n",
    "        ref_year = extract_year(ref_string)\n",
    "\n",
    "        # Find the best match in the entire corpus\n",
    "        matched_title, target_index, score = find_best_match_for_reference_v2(\n",
    "            norm_ref_title,\n",
    "            df,\n",
    "            corpus_titles_map,\n",
    "            ref_year=ref_year,\n",
    "            threshold=85, # You can tune this!\n",
    "            year_tol=2\n",
    "        )\n",
    "\n",
    "        # If a good match was found, store it\n",
    "        if target_index is not None:\n",
    "            citation_links.append({\n",
    "                'source_index': source_index,\n",
    "                'source_title': source_title,\n",
    "                'reference_string': ref_string,\n",
    "                'target_index': target_index,\n",
    "                'matched_corpus_title': df.loc[target_index, 'Title'],\n",
    "                'match_score': score\n",
    "            })\n",
    "\n",
    "# --- Step 4: Create and Analyze the Results DataFrame ---\n",
    "\n",
    "print(f\"\\nProcess complete. Found {len(citation_links)} potential links.\")\n",
    "\n",
    "# Create a new DataFrame from the results\n",
    "links_df = pd.DataFrame(citation_links)\n",
    "\n",
    "print(\"\\nSample of created links:\")\n",
    "print(links_df.head().to_string())\n",
    "\n",
    "# Analyze the distribution of match scores\n",
    "if not links_df.empty:\n",
    "    print(\"\\nDistribution of match scores:\")\n",
    "    print(links_df['match_score'].describe())\n",
    "    \n",
    "    # It's also very useful to look at the borderline cases\n",
    "    print(\"\\nExamples of borderline matches (score between 85 and 90):\")\n",
    "    borderline_cases = links_df[(links_df['match_score'] > 85) & (links_df['match_score'] < 90)]\n",
    "    print(borderline_cases.head(5).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870fe52",
   "metadata": {},
   "source": [
    "## 3 Tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fb82d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_title(title):\n",
    "    \"\"\"\n",
    "    Normalizes a paper title string, using a simple rule to detect spaced-out text.\n",
    "    Args:\n",
    "        title (str or any): The input title to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str: The normalized title string. Returns an empty string if input is not a string.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(title, str):\n",
    "        return \"\"\n",
    "\n",
    "    if \"  \" in title:\n",
    "        placeholder = \"@@@\"\n",
    "        \n",
    "        title_fixed = re.sub(r'\\s{2,}', placeholder, title)\n",
    "        \n",
    "        title_fixed = title_fixed.replace(' ', '')\n",
    "        \n",
    "        title = title_fixed.replace(placeholder, ' ')\n",
    "        \n",
    "    title = title.lower()\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    title = \" \".join(title.split())\n",
    "    \n",
    "    return title\n",
    "\n",
    "def extract_year(date_string):\n",
    "    \"\"\"\n",
    "    Extracts the most likely publication year from a messy date string.\n",
    "    Args:\n",
    "        date_string (str): The messy string from the 'Date' column.\n",
    "\n",
    "    Returns:\n",
    "        int or None: The extracted four-digit year as an integer, or None if no\n",
    "                     plausible year can be found.\n",
    "    \"\"\"\n",
    "    if not isinstance(date_string, str):\n",
    "        return None\n",
    "\n",
    "    published_match = re.search(r'Published: .*?(\\b(19|20)\\d{2}\\b)', date_string)\n",
    "    if published_match:\n",
    "        return int(published_match.group(1))\n",
    "\n",
    "    all_years = re.findall(r'\\b(?:19|20)\\d{2}\\b', date_string)\n",
    "    \n",
    "    if all_years:\n",
    "        return int(all_years[-1])\n",
    "\n",
    "    # If no year could be found, return None\n",
    "    return \"no_date\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_pickle(\"citation_links_38652.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e089387",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_pickle(\"DATASET/ED4RE_2503/ED4RE_2603.pickle\")\n",
    "is_list_mask = df['References'].apply(lambda x: isinstance(x, list))\n",
    "df_lists_only = df[is_list_mask]\n",
    "df = df_lists_only.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "646bb91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0029535293579101562,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Normalizing Titles",
       "rate": null,
       "total": 162726,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28752798b72469b9f526dd734108453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalizing Titles:   0%|          | 0/162726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0029845237731933594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting Years",
       "rate": null,
       "total": 162726,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2d23a0b3fb4e2cb1dfec1cbfe5c8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Years:   0%|          | 0/162726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building graph from 46 high-confidence links.\n",
      "Found 22 unique papers (nodes) in the network.\n",
      "\n",
      "Graph created successfully!\n",
      "--- Basic Graph Statistics ---\n",
      "Number of nodes: 22\n",
      "Number of edges: 28\n",
      "Graph density: 0.060606\n",
      "\n",
      "--- Top 10 Most Cited Papers in Your Corpus ---\n",
      "Citations: 4     | Title: business structure of electricity distribution system operator and effect on solar photovoltaic uptake an empirical case study for switzerland\n",
      "Citations: 3     | Title: are electric vehicle drivers willing to participate in vehicletogrid contracts a contextdependent stated choice experiment\n",
      "Citations: 2     | Title: recycled text and risk communication in natural gas pipeline environmental impact assessments\n",
      "Citations: 2     | Title: efficient floating offshore wind realization a comparative legal analysis of france norway and the united kingdom\n",
      "Citations: 2     | Title: time history and meaningmaking in research on peoples relations with renewable energy technologies retsa conceptual proposal\n",
      "Citations: 2     | Title: the impacts of covid19 on clean energy labor markets evidence from multifaceted analysis of public health interventions and covidhealth factors\n",
      "Citations: 1     | Title: taxing crude oil a financing alternative to mitigate climate change\n",
      "Citations: 1     | Title: comment on theuppsala critique\n",
      "Citations: 1     | Title: decarbonising europeeu citizensperception of renewable energy transition amidst the european green deal\n",
      "Citations: 1     | Title: a geographically resolved method to estimate levelized power plant costs with environmental externalities\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import networkx as nx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Normalizing Titles\")\n",
    "df['normalized_title'] = df['Title'].progress_apply(fix_title)\n",
    "\n",
    "tqdm.pandas(desc=\"Extracting Years\")\n",
    "df['year'] = df['Date'].progress_apply(extract_year)\n",
    "\n",
    "\n",
    "# Let's use the high-confidence links for a cleaner graph\n",
    "CONFIDENCE_THRESHOLD = 90\n",
    "if 'match_score' in links.columns:\n",
    "    graph_df = links[links['match_score'] >= CONFIDENCE_THRESHOLD].copy()\n",
    "else:\n",
    "    graph_df = links.copy()\n",
    "\n",
    "print(f\"Building graph from {len(graph_df)} high-confidence links.\")\n",
    "\n",
    "# 1. Identify all unique nodes from your links\n",
    "# These are all the paper indices that are either a source or a target.\n",
    "all_node_indices = pd.concat([\n",
    "    graph_df['source_index'], \n",
    "    graph_df['target_index']\n",
    "]).unique()\n",
    "\n",
    "print(f\"Found {len(all_node_indices)} unique papers (nodes) in the network.\")\n",
    "\n",
    "# 2. Get the attributes for these nodes (the titles) from the main DataFrame\n",
    "# We select only the rows from the main 'df' that correspond to our nodes.\n",
    "node_attributes_df = df.loc[all_node_indices, ['normalized_title', 'year']]\n",
    "\n",
    "# 3. Create the list of nodes in the format networkx expects:\n",
    "# [(node_id, {attribute_dict}), (node_id_2, {attribute_dict_2}), ...]\n",
    "nodes_with_attrs = [\n",
    "    (index, {\"title\": row[\"normalized_title\"], \"year\": row[\"year\"]}) \n",
    "    for index, row in node_attributes_df.iterrows()\n",
    "]\n",
    "\n",
    "# 4. Create the list of edges from your links DataFrame\n",
    "# This is a simple list of (source, target) tuples.\n",
    "edges = list(graph_df[['source_index', 'target_index']].to_records(index=False))\n",
    "\n",
    "# 1. Create a new directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# 2. Add the nodes and edges\n",
    "G.add_nodes_from(nodes_with_attrs)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "print(\"\\nGraph created successfully!\")\n",
    "print(\"--- Basic Graph Statistics ---\")\n",
    "print(f\"Number of nodes: {G.number_of_nodes():,}\")\n",
    "print(f\"Number of edges: {G.number_of_edges():,}\")\n",
    "\n",
    "# The density of a graph is the ratio of actual edges to all possible edges.\n",
    "# Citation networks are extremely sparse, so this number will be tiny.\n",
    "density = nx.density(G)\n",
    "print(f\"Graph density: {density:.6f}\")\n",
    "\n",
    "# --- Find the most influential papers (most cited) ---\n",
    "# In a citation network, this means finding the nodes with the highest \"in-degree\".\n",
    "in_degrees = G.in_degree() # This returns a list of (node, degree) tuples\n",
    "top_10_cited = sorted(in_degrees, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"\\n--- Top 10 Most Cited Papers in Your Corpus ---\")\n",
    "for node_id, degree in top_10_cited:\n",
    "    # Use the node attribute 'title' that we added earlier\n",
    "    title = G.nodes[node_id]['title']\n",
    "    print(f\"Citations: {degree:<5} | Title: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c48b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "nx.write_graphml(G, f\"citation_graph_{len(G.nodes)}.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
